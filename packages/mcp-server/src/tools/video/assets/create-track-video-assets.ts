// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

import { maybeFilter } from '@mux/mcp/filtering';
import { asTextContentResult } from '@mux/mcp/tools/types';

import { Tool } from '@modelcontextprotocol/sdk/types.js';
import type { Metadata } from '../../';
import Mux from '@mux/mux-node';

export const metadata: Metadata = {
  resource: 'video.assets',
  operation: 'write',
  tags: [],
  httpMethod: 'post',
  httpPath: '/video/v1/assets/{ASSET_ID}/tracks',
  operationId: 'create-asset-track',
};

export const tool: Tool = {
  name: 'create_track_video_assets',
  description:
    "When using this tool, always use the `jq_filter` parameter to reduce the response size and improve performance.\n\nOnly omit if you're sure you don't need the data.\n\nAdds an asset track (for example, subtitles, or an alternate audio track) to an asset. Assets must be in the `ready` state before tracks can be added.\n\n# Response Schema\n```json\n{\n  type: 'object',\n  properties: {\n    data: {\n      $ref: '#/$defs/track'\n    }\n  },\n  required: [    'data'\n  ],\n  $defs: {\n    track: {\n      type: 'object',\n      properties: {\n        id: {\n          type: 'string',\n          description: 'Unique identifier for the Track'\n        },\n        closed_captions: {\n          type: 'boolean',\n          description: 'Indicates the track provides Subtitles for the Deaf or Hard-of-hearing (SDH). This parameter is only set tracks where `type` is `text` and `text_type` is `subtitles`.'\n        },\n        duration: {\n          type: 'number',\n          description: 'The duration in seconds of the track media. This parameter is not set for `text` type tracks. This field is optional and may not be set. The top level `duration` field of an asset will always be set.'\n        },\n        language_code: {\n          type: 'string',\n          description: 'The language code value represents [BCP 47](https://tools.ietf.org/html/bcp47) specification compliant value. For example, `en` for English or `en-US` for the US version of English. This parameter is only set for `text` and `audio` track types.'\n        },\n        max_channel_layout: {\n          type: 'string',\n          description: 'Only set for the `audio` type track.'\n        },\n        max_channels: {\n          type: 'integer',\n          description: 'The maximum number of audio channels the track supports. Only set for the `audio` type track.'\n        },\n        max_frame_rate: {\n          type: 'number',\n          description: 'The maximum frame rate available for the track. Only set for the `video` type track. This field may return `-1` if the frame rate of the input cannot be reliably determined.'\n        },\n        max_height: {\n          type: 'integer',\n          description: 'The maximum height in pixels available for the track. Only set for the `video` type track.'\n        },\n        max_width: {\n          type: 'integer',\n          description: 'The maximum width in pixels available for the track. Only set for the `video` type track.'\n        },\n        name: {\n          type: 'string',\n          description: 'The name of the track containing a human-readable description. The HLS manifest will associate a subtitle `text` or `audio` track with this value. For example, the value should be \"English\" for a subtitle text track for the `language_code` value of `en-US`. This parameter is only set for `text` and `audio` track types.'\n        },\n        passthrough: {\n          type: 'string',\n          description: 'Arbitrary user-supplied metadata set for the track either when creating the asset or track. This parameter is only set for `text` type tracks. Max 255 characters.'\n        },\n        primary: {\n          type: 'boolean',\n          description: 'For an audio track, indicates that this is the primary audio track, ingested from the main input for this asset. The primary audio track cannot be deleted.'\n        },\n        status: {\n          type: 'string',\n          description: 'The status of the track. This parameter is only set for `text` type tracks.',\n          enum: [            'preparing',\n            'ready',\n            'errored',\n            'deleted'\n          ]\n        },\n        text_source: {\n          type: 'string',\n          description: 'The source of the text contained in a Track of type `text`. Valid `text_source`\\nvalues are listed below.\\n* `uploaded`: Tracks uploaded to Mux as caption or subtitle files using the Create Asset Track API.\\n* `embedded`: Tracks extracted from an embedded stream of CEA-608 closed captions.\\n* `generated_vod`: Tracks generated by automatic speech recognition on an on-demand asset.\\n* `generated_live`: Tracks generated by automatic speech recognition on a live stream configured with `generated_subtitles`. If an Asset has both `generated_live` and `generated_live_final` tracks that are `ready`, then only the `generated_live_final` track will be included during playback.\\n* `generated_live_final`: Tracks generated by automatic speech recognition on a live stream using `generated_subtitles`. The accuracy, timing, and formatting of these subtitles is improved compared to the corresponding `generated_live` tracks. However, `generated_live_final` tracks will not be available in `ready` status until the live stream ends. If an Asset has both `generated_live` and `generated_live_final` tracks that are `ready`, then only the `generated_live_final` track will be included during playback.',\n          enum: [            'uploaded',\n            'embedded',\n            'generated_live',\n            'generated_live_final',\n            'generated_vod'\n          ]\n        },\n        text_type: {\n          type: 'string',\n          description: 'This parameter is only set for `text` type tracks.',\n          enum: [            'subtitles'\n          ]\n        },\n        type: {\n          type: 'string',\n          description: 'The type of track',\n          enum: [            'video',\n            'audio',\n            'text'\n          ]\n        }\n      },\n      required: []\n    }\n  }\n}\n```",
  inputSchema: {
    type: 'object',
    properties: {
      ASSET_ID: {
        type: 'string',
      },
      language_code: {
        type: 'string',
        description:
          'The language code value must be a valid BCP 47 specification compliant value. For example, en for English or en-US for the US version of English.',
      },
      type: {
        type: 'string',
        enum: ['text', 'audio'],
      },
      url: {
        type: 'string',
        description:
          'The URL of the file that Mux should download and use.\n* For `audio` tracks, the URL is the location of the audio file for Mux to download, for example an M4A, WAV, or MP3 file. Mux supports most audio file formats and codecs, but for fastest processing, you should [use standard inputs wherever possible](https://docs.mux.com/guides/minimize-processing-time).\n* For `text` tracks, the URL is the location of subtitle/captions file. Mux supports [SubRip Text (SRT)](https://en.wikipedia.org/wiki/SubRip) and [Web Video Text Tracks](https://www.w3.org/TR/webvtt1/) formats for ingesting Subtitles and Closed Captions.\n',
      },
      closed_captions: {
        type: 'boolean',
        description: 'Indicates the track provides Subtitles for the Deaf or Hard-of-hearing (SDH).',
      },
      name: {
        type: 'string',
        description:
          'The name of the track containing a human-readable description. This value must be unique within each group of `text` or `audio` track types. The HLS manifest will associate the `text` or `audio` track with this value. For example, set the value to "English" for subtitles text track with `language_code` as en-US. If this parameter is not included, Mux will auto-populate a value based on the `language_code` value.',
      },
      passthrough: {
        type: 'string',
        description:
          'Arbitrary user-supplied metadata set for the track either when creating the asset or track.',
      },
      text_type: {
        type: 'string',
        enum: ['subtitles'],
      },
      jq_filter: {
        type: 'string',
        title: 'jq Filter',
        description:
          'A jq filter to apply to the response to include certain fields. Consult the output schema in the tool description to see the fields that are available.\n\nFor example: to include only the `name` field in every object of a results array, you can provide ".results[].name".\n\nFor more information, see the [jq documentation](https://jqlang.org/manual/).',
      },
    },
  },
};

export const handler = async (client: Mux, args: Record<string, unknown> | undefined) => {
  const { ASSET_ID, ...body } = args as any;
  return asTextContentResult(await maybeFilter(args, await client.video.assets.createTrack(ASSET_ID, body)));
};

export default { metadata, tool, handler };
